# Digit recognition using Logistic Regression, Softmax and Gradient Descent
> This repository contains Python scripts for implementing softmax and logistic regression models to recognize handwritten digits from the MNIST dataset.
> 

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Navigation

- [Overview](#overview)
- [Visualizations](#Visualizations)
- [Conclusion](#Conclusion)

## Overview

### Goals

- To implement Softmax function to distinguisch between the numbers in the dataset.
- To implement gradient descent and Newton methods to minimize functions.
- To try different stepwise methods(Powel Wolfe, Armijo, constant) and understand their pros and cons.

### Dataset 

- MNIST dataset

### Model

- ##Softmax Regression:
- A multi-class logistic regression model using the softmax function.
